<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Changelog • tidyprompt</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Changelog"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyprompt</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/creating_prompt_wraps.html">Creating prompt wraps</a></li>
    <li><a class="dropdown-item" href="../articles/getting_started.html">Getting started</a></li>
    <li><a class="dropdown-item" href="../articles/sentiment_analysis.html">Sentiment analysis in R with a LLM and 'tidyprompt'</a></li>
  </ul></li>
<li class="active nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/KennispuntTwente/tidyprompt/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-news">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Changelog</h1>
      <small>Source: <a href="https://github.com/KennispuntTwente/tidyprompt/blob/0.2.0/NEWS.md" class="external-link"><code>NEWS.md</code></a></small>
    </div>

    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.2.0" id="tidyprompt-020">tidyprompt 0.2.0<a class="anchor" aria-label="anchor" href="#tidyprompt-020"></a></h2><p class="text-muted">CRAN release: 2025-08-25</p>
<ul><li><p>Add provider-level prompt wraps (<code><a href="../reference/provider_prompt_wrap.html">provider_prompt_wrap()</a></code>) these are prompt wraps which can be attached to a LLM provider object. They can be applied to any prompt which is sent through this LLM provider, either before or after prompt-specific prompt wraps. This is useful when you want to achieve certain behavior for various prompts, without having to re-apply the same prompt wrap to each prompt</p></li>
<li><p><code><a href="../reference/answer_as_json.html">answer_as_json()</a></code>: support ‘ellmer’ definitions of structured output (e.g., <code><a href="https://ellmer.tidyverse.org/reference/type_boolean.html" class="external-link">ellmer::type_object()</a></code>). <code><a href="../reference/answer_as_json.html">answer_as_json()</a></code> can convert between ellmer definitions and the previous R list objects which represent JSON schemas; thus, ‘ellmer’ and R list object definitions work with both regular and ‘ellmer’ LLM providers. When using an <code><a href="../reference/llm_provider_ellmer.html">llm_provider_ellmer()</a></code>, <code><a href="../reference/answer_as_json.html">answer_as_json()</a></code> will ensure the native ‘ellmer’ functions for obtaining structured output are used</p></li>
<li><p><code><a href="../reference/answer_using_tools.html">answer_using_tools()</a></code>: support ‘ellmer’ definitions of tools (from <code><a href="https://ellmer.tidyverse.org/reference/tool.html" class="external-link">ellmer::tool()</a></code>). <code><a href="../reference/answer_using_tools.html">answer_using_tools()</a></code> can convert between ‘ellmer’ tool definitions and the previous R function objects with documentation from <code><a href="../reference/tools_add_docs.html">tools_add_docs()</a></code>; thus, ‘ellmer’ and <code><a href="../reference/tools_add_docs.html">tools_add_docs()</a></code> definitions work with both regular and ‘ellmer’ LLM providers. When using an <code><a href="../reference/llm_provider_ellmer.html">llm_provider_ellmer()</a></code>, <code><a href="../reference/answer_using_tools.html">answer_using_tools()</a></code> will ensure the native ‘ellmer’ functions for registering tools are used.</p></li>
<li><p><code><a href="../reference/answer_using_tools.html">answer_using_tools()</a></code>: because of the above, and the fact that package ‘mcptools’ returns ‘ellmer’ tool definitions with <code><a href="https://posit-dev.github.io/mcptools/reference/client.html" class="external-link">mcptools::mcp_tools()</a></code>, <code><a href="../reference/answer_using_tools.html">answer_using_tools()</a></code> can now also be used with tools from Model Context Protocol (MCP) servers</p></li>
<li><p><code><a href="../reference/send_prompt.html">send_prompt()</a></code> can now return an updated ‘ellmer’ chat object when using an <code><a href="../reference/llm_provider_ellmer.html">llm_provider_ellmer()</a></code> (containing for instance the history of ‘ellmer’ turns and tool calls). Additionally fixed issues with how turn history is handled in ‘ellmer’ chat objects</p></li>
<li><p><code><a href="../reference/send_prompt.html">send_prompt()</a></code>’s <code>clean_chat_history</code> argument is now defaulted to <code>FALSE</code>, as it may be confusing for users to see cleaned chat histories without having actively requested this. If <code>return_mode = "full"</code>, <code>$clean_chat_history</code> is also no longer included when <code>clean_chat_history = FALSE</code></p></li>
<li><p><code><a href="../reference/llm_provider_openai.html">llm_provider_openai()</a></code> now supports (as default) the OpenAI responses API, which allows setting parameters like ‘reasoning_effort’ and ‘verbosity’ (relevant for gpt-5). The OpenAI chat completions API is also still supported</p></li>
<li><p><code><a href="../reference/llm_provider_google_gemini.html">llm_provider_google_gemini()</a></code> has been superseded by <code>llm_provider_ellmer(ellmer::chat_google_gemini())</code></p></li>
<li><p>Add a <code>json_type</code> &amp; <code>tool_type</code> field to LLM provider objects; when automatically determining the route towards structured output (in <code><a href="../reference/answer_as_json.html">answer_as_json()</a></code>) and tool use (in <code><a href="../reference/answer_using_tools.html">answer_using_tools()</a></code>), this can override the type decided by the <code>api_type</code> field (e.g., user can use this field to force the text-based type, for instance when using an OpenAI type LLM provider but with a model which does not support the typical OpenAI API parameters for structured output)</p></li>
<li><p>Update how responses are streamed (with <code><a href="https://httr2.r-lib.org/reference/req_perform_connection.html" class="external-link">httr2::req_perform_connection()</a></code>, since <code><a href="https://httr2.r-lib.org/reference/req_perform_stream.html" class="external-link">httr2::req_perform_stream()</a></code> is being deprecated)</p></li>
<li><p>Fix bug where the LLM provider object was not properly passed on to <code>modify_fn</code> in <code><a href="../reference/prompt_wrap.html">prompt_wrap()</a></code>, which could lead to errors when dynamically constructing prompt text based on the LLM provider type</p></li>
</ul></div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.0" id="tidyprompt-010">tidyprompt 0.1.0<a class="anchor" aria-label="anchor" href="#tidyprompt-010"></a></h2><p class="text-muted">CRAN release: 2025-08-18</p>
<ul><li><p>New prompt wraps <code><a href="../reference/answer_as_category.html">answer_as_category()</a></code> and <code><a href="../reference/answer_as_multi_category.html">answer_as_multi_category()</a></code></p></li>
<li><p>New <code><a href="../reference/llm_break_soft.html">llm_break_soft()</a></code> interrupts prompt evaluation without error</p></li>
<li><p>New experimental provider <code><a href="../reference/llm_provider_ellmer.html">llm_provider_ellmer()</a></code> for <code>ellmer</code> chat objects</p></li>
<li><p>Ollama provider gains <code>num_ctx</code> parameter to control context window size</p></li>
<li><p><code>set_option()</code> and <code>set_options()</code> are now available for the Ollama provider to configure options</p></li>
<li><p>Error messages are more informative when an LLM provider cannot be reached</p></li>
<li><p>Google Gemini provider now works without errors in affected cases</p></li>
<li><p>Chat history handling is safer; rows with <code>NA</code> values no longer cause errors in specific cases</p></li>
<li><p>Final-answer extraction in chain-of-thought prompts is more flexible</p></li>
<li><p>Printed LLM responses now use <code><a href="https://rdrr.io/r/base/message.html" class="external-link">message()</a></code> instead of <code><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat()</a></code></p></li>
<li><p>Moved repository to <a href="https://github.com/KennispuntTwente/tidyprompt" class="external-link uri">https://github.com/KennispuntTwente/tidyprompt</a></p></li>
</ul></div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.0.1" id="tidyprompt-001">tidyprompt 0.0.1<a class="anchor" aria-label="anchor" href="#tidyprompt-001"></a></h2><p class="text-muted">CRAN release: 2025-01-08</p>
<ul><li>Initial CRAN release</li>
</ul></div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.0.0.9000" id="tidyprompt-0009000">tidyprompt 0.0.0.9000<a class="anchor" aria-label="anchor" href="#tidyprompt-0009000"></a></h2>
<ul><li>Initial development version available on GitHub</li>
</ul></div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Luka Koning, Tjark Van de Merwe, Kennispunt Twente.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

