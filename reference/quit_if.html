<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Make evaluation of a prompt stop if LLM gives a specific response — quit_if • tidyprompt</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Make evaluation of a prompt stop if LLM gives a specific response — quit_if"><meta name="description" content="This function is used to wrap a tidyprompt() object and ensure that the
evaluation will stop if the LLM says it cannot answer the prompt. This is
useful in scenarios where it is determined the LLM is unable to provide a
response to a prompt."><meta property="og:description" content="This function is used to wrap a tidyprompt() object and ensure that the
evaluation will stop if the LLM says it cannot answer the prompt. This is
useful in scenarios where it is determined the LLM is unable to provide a
response to a prompt."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyprompt</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/creating_prompt_wraps.html">Creating prompt wraps</a></li>
    <li><a class="dropdown-item" href="../articles/getting_started.html">Getting started</a></li>
    <li><a class="dropdown-item" href="../articles/sentiment_analysis.html">Sentiment analysis in R with a LLM and 'tidyprompt'</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tjarkvandemerwe/tidyprompt/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Make evaluation of a prompt stop if LLM gives a specific response</h1>
      <small class="dont-index">Source: <a href="https://github.com/tjarkvandemerwe/tidyprompt/blob/main/R/quit_if.R" class="external-link"><code>R/quit_if.R</code></a></small>
      <div class="d-none name"><code>quit_if.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>This function is used to wrap a <code><a href="tidyprompt.html">tidyprompt()</a></code> object and ensure that the
evaluation will stop if the LLM says it cannot answer the prompt. This is
useful in scenarios where it is determined the LLM is unable to provide a
response to a prompt.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">quit_if</span><span class="op">(</span></span>
<span>  <span class="va">prompt</span>,</span>
<span>  quit_detect_regex <span class="op">=</span> <span class="st">"NO ANSWER"</span>,</span>
<span>  instruction <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"If you think that you cannot provide a valid answer, you must type:\n"</span>,</span>
<span>    <span class="st">"'NO ANSWER' (use no other characters)"</span><span class="op">)</span>,</span>
<span>  success <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  response_result <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"null"</span>, <span class="st">"llm_response"</span>, <span class="st">"regex_match"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-prompt">prompt<a class="anchor" aria-label="anchor" href="#arg-prompt"></a></dt>
<dd><p>A single string or a <code><a href="tidyprompt.html">tidyprompt()</a></code> object</p></dd>


<dt id="arg-quit-detect-regex">quit_detect_regex<a class="anchor" aria-label="anchor" href="#arg-quit-detect-regex"></a></dt>
<dd><p>A regular expression to detect in the LLM's
response which will cause the evaluation to stop. The default
will detect the string "NO ANSWER" in the response</p></dd>


<dt id="arg-instruction">instruction<a class="anchor" aria-label="anchor" href="#arg-instruction"></a></dt>
<dd><p>A string to be added to the prompt to instruct the LLM
how to respond if it cannot answer the prompt. The default is
"If you think that you cannot provide a valid answer, you must type: 'NO ANSWER' (use no other characters)".
This parameter can be set to <code>NULL</code> if no instruction is needed in the prompt</p></dd>


<dt id="arg-success">success<a class="anchor" aria-label="anchor" href="#arg-success"></a></dt>
<dd><p>A logical indicating whether the <code><a href="send_prompt.html">send_prompt()</a></code> loop break
should nonetheless be considered as a successful completion of the
extraction and validation process. If <code>FALSE</code>, the <code>object_to_return</code> must
will always be set to NULL and thus parameter 'response_result' must also
be set to 'null'; if <code>FALSE</code>, <code><a href="send_prompt.html">send_prompt()</a></code> will also print a warning
about the unsuccessful evaluation. If <code>TRUE</code>, the <code>object_to_return</code> will be
returned as the response result of <code><a href="send_prompt.html">send_prompt()</a></code> (and <code><a href="send_prompt.html">send_prompt()</a></code>
will print no warning about unsuccessful evaluation); parameter 'response_result'
will then determine what is returned as the response result of <code><a href="send_prompt.html">send_prompt()</a></code>.</p></dd>


<dt id="arg-response-result">response_result<a class="anchor" aria-label="anchor" href="#arg-response-result"></a></dt>
<dd><p>A character string indicating what should be returned
when the quit_detect_regex is detected in the LLM's response. The default is
'null', which will return NULL as the response result o f <code><a href="send_prompt.html">send_prompt()</a></code>.
Under 'llm_response', the full LLM response will be returned as the
response result of <code><a href="send_prompt.html">send_prompt()</a></code>.
Under 'regex_match', the part of the LLM response that matches the
quit_detect_regex will be returned as the response result of <code><a href="send_prompt.html">send_prompt()</a></code></p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A <code><a href="tidyprompt.html">tidyprompt()</a></code> with an added <code><a href="prompt_wrap.html">prompt_wrap()</a></code> which will ensure
that the evaluation will stop upon detection of the quit_detect_regex in the
LLM's response</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p>Other pre_built_prompt_wraps:
<code><a href="add_text.html">add_text</a>()</code>,
<code><a href="answer_as_boolean.html">answer_as_boolean</a>()</code>,
<code><a href="answer_as_integer.html">answer_as_integer</a>()</code>,
<code><a href="answer_as_json.html">answer_as_json</a>()</code>,
<code><a href="answer_as_list.html">answer_as_list</a>()</code>,
<code><a href="answer_as_named_list.html">answer_as_named_list</a>()</code>,
<code><a href="answer_as_regex.html">answer_as_regex</a>()</code>,
<code><a href="answer_as_text.html">answer_as_text</a>()</code>,
<code><a href="answer_by_chain_of_thought.html">answer_by_chain_of_thought</a>()</code>,
<code><a href="answer_by_react.html">answer_by_react</a>()</code>,
<code><a href="answer_using_r.html">answer_using_r</a>()</code>,
<code><a href="answer_using_sql.html">answer_using_sql</a>()</code>,
<code><a href="answer_using_tools.html">answer_using_tools</a>()</code>,
<code><a href="prompt_wrap.html">prompt_wrap</a>()</code>,
<code><a href="set_system_prompt.html">set_system_prompt</a>()</code></p>
<p>Other miscellaneous_prompt_wraps:
<code><a href="add_text.html">add_text</a>()</code>,
<code><a href="set_system_prompt.html">set_system_prompt</a>()</code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span>  <span class="st">"What the favourite food of my cat on Thursday mornings?"</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="fu">quit_if</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="fu"><a href="llm_provider_ollama.html">llm_provider_ollama</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="co"># --- Sending request to LLM provider (llama3.1:8b): ---</span></span></span>
<span class="r-in"><span>  <span class="co">#   What the favourite food of my cat on Thursday mornings?</span></span></span>
<span class="r-in"><span>  <span class="co">#</span></span></span>
<span class="r-in"><span>  <span class="co">#   If you think that you cannot provide a valid answer, you must type:</span></span></span>
<span class="r-in"><span>  <span class="co">#   'NO ANSWER' (use no other characters)</span></span></span>
<span class="r-in"><span>  <span class="co"># --- Receiving response from LLM provider: ---</span></span></span>
<span class="r-in"><span>  <span class="co">#   NO ANSWER</span></span></span>
<span class="r-in"><span>  <span class="co"># NULL</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Luka Koning, Tjark Van de Merwe, Kennispunt Twente.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

