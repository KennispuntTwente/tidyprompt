<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>tidyprompt: AI Coding Agent Instructions • tidyprompt</title><script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="tidyprompt: AI Coding Agent Instructions"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">tidyprompt</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="articles/creating_prompt_wraps.html">Creating prompt wraps</a></li>
    <li><a class="dropdown-item" href="articles/getting_started.html">Getting started</a></li>
    <li><a class="dropdown-item" href="articles/sentiment_analysis.html">Sentiment analysis in R with a LLM and 'tidyprompt'</a></li>
    <li><a class="dropdown-item" href="articles/streaming_shiny_ipc.html">Streaming LLM responses to Shiny apps</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/KennispuntTwente/tidyprompt/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-title-body">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>tidyprompt: AI Coding Agent Instructions</h1>
      <small class="dont-index">Source: <a href="https://github.com/KennispuntTwente/tidyprompt/blob/main/.github/copilot-instructions.md" class="external-link"><code>.github/copilot-instructions.md</code></a></small>
    </div>

<div id="tidyprompt-ai-coding-agent-instructions" class="section level1">

<p>These instructions summarize project-specific architecture, patterns, and workflows so an AI agent can contribute productively. Keep advice concrete and tied to existing code (not aspirational). Refer to files with backticks.</p>
<div class="section level2">
<h2 id="core-architecture">Core Architecture<a class="anchor" aria-label="anchor" href="#core-architecture"></a></h2>
<ul><li>Pipeline design: Prompts are progressively transformed via chained prompt wraps (see <code>R/prompt_wrap.R</code>) using native R pipe <code>|&gt;</code>. Each wrap can modify text (<code>modify_fn</code>), extract, validate, handle provider responses (<code>handler_fn</code>), or set provider parameters (<code>parameter_fn</code>).</li>
<li>Wrap type ordering (critical): Modification phase applies in order <code>check</code>, <code>unspecified</code>, <code><a href="https://rdrr.io/r/base/Control.html" class="external-link">break</a></code>, <code>mode</code>, <code>tool</code>; evaluation phase reverses: <code>tool</code>, <code>mode</code>, <code><a href="https://rdrr.io/r/base/Control.html" class="external-link">break</a></code>, <code>unspecified</code>, <code>check</code> (tests assert this in <code>tests/testthat/test-prompt_wrap.R</code>). Breaking this order will cause subtle extraction/validation failures.</li>
<li>Interaction loop: <code><a href="reference/send_prompt.html">send_prompt()</a></code> (see <code>R/send_prompt.R</code>) drives retries until success or <code>max_interactions</code>. It applies extraction then validation for each wrap, sending <code><a href="reference/llm_feedback.html">llm_feedback()</a></code> messages back for correction. <code><a href="reference/llm_break.html">llm_break()</a></code> / <code><a href="reference/llm_break_soft.html">llm_break_soft()</a></code> short-circuit evaluation; on break, remaining <code>check</code> wraps may still run.</li>
<li>Provider abstraction: R6 class <code>llm_provider-class</code> (<code>R/llm_provider.R</code>) exposes <code>$complete_chat()</code>, <code>$add_handler_fn()</code>, <code>$add_prompt_wrap()</code>. Concrete providers implemented in <code>R/llm_providers.R</code> (Ollama, OpenAI, Mistral, Groq, OpenRouter, etc.) wrap HTTP calls in a uniform response object with <code>completed</code>, <code>http</code>, optional <code>ellmer_chat</code>.</li>
<li>Provider-level wraps: Use <code><a href="reference/provider_prompt_wrap.html">provider_prompt_wrap()</a></code> + <code>$add_prompt_wrap(position = "pre"|"post")</code> to enforce global behaviors. They are injected before user wraps in <code><a href="reference/send_prompt.html">send_prompt()</a></code>.</li>
<li>Streaming: Controlled by provider <code>parameters$stream</code>; optional <code>stream_callback</code> (see field in <code>llm_provider-class</code>) receives <code>(chunk, meta)</code> for incremental output (examples in vignette <code>streaming_shiny_ipc.Rmd</code>). Agents adding streaming features must respect existing callback signature.</li>
</ul></div>
<div class="section level2">
<h2 id="key-conventions--patterns">Key Conventions &amp; Patterns<a class="anchor" aria-label="anchor" href="#key-conventions--patterns"></a></h2>
<ul><li>Function naming: User-facing wraps start with <code>answer_</code> / <code>answer_by_</code> / verbs like <code>add_</code> (<code>answer_as_json.R</code>, <code>answer_by_chain_of_thought.R</code>, <code>add_text.R</code>). Internal helpers prefixed <code>helper_</code> or <code>internal_</code> (e.g. <code>internal_request_llm_provider.R</code>). Maintain these prefixes when adding similar functionality.</li>
<li>Wrap construction: At least one of <code>modify_fn</code>, <code>extraction_fn</code>, <code>validation_fn</code>, <code>handler_fn</code>, <code>parameter_fn</code> must be non-NULL (enforced in <code>prompt_wrap_internal</code>). Type <code>check</code> allows ONLY <code>validation_fn</code>.</li>
<li>Arity normalization: <code>prompt_wrap_internal()</code> auto-expands formals so extraction/validation/modify functions optionally accept <code>(x, llm_provider, http_list)</code>. When adding new wrap functions, write the first argument (content) only; extra params are appended automatically.</li>
<li>Feedback protocol: Extraction/validation return either the processed value, <code><a href="reference/llm_feedback.html">llm_feedback()</a></code> (triggers another provider request), or <code><a href="reference/llm_break.html">llm_break()</a></code> / <code><a href="reference/llm_break_soft.html">llm_break_soft()</a></code> objects to halt. Ensure new feedback objects inherit correct S3 class so loop logic detects them.</li>
<li>Tool use &amp; structured output: <code><a href="reference/answer_using_tools.html">answer_using_tools()</a></code> and <code><a href="reference/answer_as_json.html">answer_as_json()</a></code> handle native provider modes vs text-based fallback. They map provider <code>$api_type</code> or explicit <code>$tool_type</code> / <code>$json_type</code> to behavior. New structured modes should follow this pattern: detect native support; else inject instructions via <code>modify_fn</code> and parse with <code>extraction_fn</code>.</li>
<li>Environment passing for tools: <code>prompt_wrap_internal()</code> copies an <code>environment</code> attribute onto extraction functions (tool execution context). Preserve this when extending tool functionality.</li>
<li>Handler loop semantics: Provider <code>$complete_chat()</code> runs added handler functions until <code>response$done != FALSE</code>; a handler can set <code>break = TRUE</code> to abort (see <code>llm_provider.R</code>). Handlers must return the full response shape; tests enforce invariants.</li>
</ul></div>
<div class="section level2">
<h2 id="testing-workflow">Testing Workflow<a class="anchor" aria-label="anchor" href="#testing-workflow"></a></h2>
<ul><li>Tests live in <code>tests/testthat/</code>; each feature has a dedicated file (e.g. <code>test-answer-as-json.R</code>, <code>test-send_prompt.R</code>). Follow this granularity when adding features.</li>
<li>Fake provider: Use <code>llm_provider_fake()</code> (defined in provider sources) for deterministic tests (see <code>test-general.R</code>, <code>test-send_prompt.R</code>). Prefer fake over live HTTP in unit tests.</li>
<li>Assertions: Use <code>expect_s3_class</code>, <code>expect_length</code>, <code>expect_true</code>, <code>expect_equal</code>, <code>expect_no_error</code>. Mirror existing style; avoid custom matchers unless necessary.</li>
<li>To run: In R: <code>devtools::test()</code>; full checks: <code>devtools::check()</code> or shell: <code>R CMD check .</code>.</li>
</ul></div>
<div class="section level2">
<h2 id="development-workflow">Development Workflow<a class="anchor" aria-label="anchor" href="#development-workflow"></a></h2>
<ul><li>Roxygen: Add documentation headers similar to existing files (e.g. <code>@family</code> tags group wrap types). Run <code>devtools::document()</code> after changes.</li>
<li>Adding a new provider: Implement local <code>complete_chat(chat_history)</code> capturing messages, building a request via <code>httr2</code>, then delegate to <code>request_llm_provider()</code>. Expose provider-specific helpers (see Ollama <code>$set_option()</code> pattern) through an extended R6 subclass.</li>
<li>Adding a new prompt wrap helper (e.g. <code>answer_as_matrix()</code>): 1) Create <code>R/answer_as_matrix.R</code> with a user-facing function assembling a call to <code><a href="reference/prompt_wrap.html">prompt_wrap()</a></code>; 2) Provide <code>modify_fn</code> instructions; 3) Write <code>extraction_fn</code> parsing text to target structure and returning <code><a href="reference/llm_feedback.html">llm_feedback()</a></code> on failure; 4) Optional <code>validation_fn</code> for stricter constraints; 5) Add tests mirroring integer/list pattern.</li>
<li>Performance considerations: Use <code>clean_chat_history = TRUE</code> in high-retry contexts to trim earlier failed assistant messages (only last attempt kept). Respect existing shape when modifying loop logic.</li>
</ul></div>
<div class="section level2">
<h2 id="integration-points">Integration Points<a class="anchor" aria-label="anchor" href="#integration-points"></a></h2>
<ul><li>Ellmer compatibility: When provider is built from ellmer chat object (<code><a href="reference/llm_provider_ellmer.html">llm_provider_ellmer()</a></code>), updated <code>ellmer_chat</code> is synced before handler execution enabling cost/budget checks. Preserve this sync if extending handlers.</li>
<li>MCP tool definitions: <code><a href="reference/answer_using_tools.html">answer_using_tools()</a></code> supports MCP via ellmer tool objects; ensure any new tool abstraction returns compatible definitions.</li>
</ul></div>
<div class="section level2">
<h2 id="guardrails-for-agents">Guardrails for Agents<a class="anchor" aria-label="anchor" href="#guardrails-for-agents"></a></h2>
<ul><li>Do NOT change wrap ordering logic or break arity normalization without updating corresponding tests.</li>
<li>Avoid sending internal parameters (prefixed with <code>.</code>) to external APIs (OpenAI code filters these out). Replicate that pattern for new providers.</li>
<li>Keep handler side effects idempotent; they may run multiple cycles while <code>done == FALSE</code>.</li>
<li>Preserve S3 class names (<code>Tidyprompt</code>, <code>prompt_wrap</code>) to avoid downstream method breakage.</li>
</ul></div>
<div class="section level2">
<h2 id="quick-reference">Quick Reference<a class="anchor" aria-label="anchor" href="#quick-reference"></a></h2>
<ul><li>Build + docs: <code>devtools::document()</code>
</li>
<li>Run tests: <code>devtools::test()</code>
</li>
<li>Full check: <code>R CMD check .</code>
</li>
<li>Example prompt: <code>"What is 2+2?" |&gt; answer_as_integer() |&gt; send_prompt(llm_provider_ollama())</code>
</li>
</ul><p>Provide feedback if adding new features; ensure tests and documentation accompany changes.</p>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Luka Koning, Tjark Van de Merwe, Kennispunt Twente.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

