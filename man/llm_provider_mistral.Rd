% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_provider.R
\name{llm_provider_mistral}
\alias{llm_provider_mistral}
\title{Create a new Mistral \code{\link[=llm_provider]{llm_provider()}} instance}
\usage{
llm_provider_mistral(
  parameters = list(model = "ministral-3b-latest", stream =
    getOption("tidyprompt.stream", TRUE)),
  verbose = getOption("tidyprompt.verbose", TRUE),
  url = "https://api.mistral.ai/v1/chat/completions",
  api_key = Sys.getenv("MISTRAL_API_KEY")
)
}
\arguments{
\item{parameters}{A named list of parameters. Currently the following parameters are required:
\itemize{
\item model: The name of the model to use
\item stream: A logical indicating whether the API should stream responses
Additional parameters are appended to the request body; see the Mistral API
documentation for more information: https://docs.mistral.ai/api/#tag/chat
}}

\item{verbose}{A logical indicating whether the interaction with the LLM provider
should be printed to the consol}

\item{url}{The URL to the Mistral API endpoint for chat completion}

\item{api_key}{The API key to use for authentication with the Mistral API}
}
\value{
A new \code{\link[=llm_provider]{llm_provider()}} object for use of the Mistral API
}
\description{
This function creates a new \code{\link[=llm_provider]{llm_provider()}} that interacts with the Mistral API.
}
\seealso{
Other llm_provider: 
\code{\link{llm_provider}},
\code{\link{llm_provider_fake}()},
\code{\link{llm_provider_google_gemini}()},
\code{\link{llm_provider_groq}()},
\code{\link{llm_provider_ollama}()},
\code{\link{llm_provider_openai}()},
\code{\link{llm_provider_openrouter}()},
\code{\link{llm_provider_xai}()},
\code{\link{make_llm_provider_request}()}
}
\concept{llm_provider}
