% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/add_tools.R
\name{add_tools}
\alias{add_tools}
\title{Enable R function calling for prompt evaluation by a LLM}
\usage{
add_tools(prompt, tool_functions = list())
}
\arguments{
\item{prompt}{A single string or a \code{\link[=tidyprompt]{tidyprompt()}} object}

\item{tool_functions}{An R function or a list of R functions that the LLM can call.
If the function has been documented in a help file (e.g., because it is part of a
package), the documentation will be parsed from the help file. If it is a custom
function, documentation should be added with \code{\link[=add_tools_add_documentation]{add_tools_add_documentation()}}}
}
\value{
A \code{\link[=tidyprompt]{tidyprompt()}} with an added \code{\link[=prompt_wrap]{prompt_wrap()}} which
will allow the LLM to call R functions
}
\description{
This function adds the ability for the a LLM to call R functions.
Users can specify a list of functions that the LLM can call, and the
prompt will be modified to include information, as well as an
accompanying extraction function to call the functions (handled by
\code{\link[=send_prompt]{send_prompt()}}). Documentation for the functions is extracted from
the help file (if available), or from documentation added by
\code{\link[=add_tools_add_documentation]{add_tools_add_documentation()}}.
}
\details{
Note that this method of function calling is purely text-based.
This makes it suitable for any LLM and any LLM provider. However,
'native' function calling (where the LLM model provider restricts the
model to special tokens that can be used to call functions) may perform
better in terms of accuracy and efficiency. 'tidyprompt' may support
'native' function calling in the future
}
\examples{
# Example fake weather function to add to the prompt:
temperature_in_location <- function(
    location = c("Amsterdam", "Utrecht", "Enschede"),
    unit = c("Celcius", "Fahrenheit")
) {
  location <- match.arg(location)
  unit <- match.arg(unit)

  temperature_celcius <- switch(
    location,
    "Amsterdam" = 32.5,
    "Utrecht" = 19.8,
    "Enschede" = 22.7
  )

  if (unit == "Celcius") {
    return(temperature_celcius)
  } else {
    return(temperature_celcius * 9/5 + 32)
  }
}

# Add documentation to the function:
temperature_in_location <- add_tools_add_documentation(
  temperature_in_location,
  description = "Get the temperature in a location",
  arguments = list(
    location = "Location, must be one of: 'Amsterdam', 'Utrecht', 'Enschede'",
    unit = "Unit, must be one of: 'Celcius', 'Fahrenheit'"
  ),
  return_value = "The temperature in the specified location and unit"
)

# Attempt to extract documentation as it is extracted by add_tools():
add_tools_get_documentation(temperature_in_location)

# You can also pass functions which are included in packages;
#   documentation is then extracted from help files:
add_tools_get_documentation(list.files)

# Example usage:
prompt1 <- "Hi, what is the weather in Enschede? Give me Celcius degrees" |>
  add_tools(temperature_in_location)

prompt2 <- "What are the files in my current directory?" |>
  add_tools(list.files)

\dontrun{
  prompt1 |>
    send_prompt(llm_provider_ollama())
  #   --- Sending request to LLM provider (llama3.1:8b): ---
  #     Hi, what is the weather in Enschede? Give me Celcius degrees
  #
  #     If you need more information, you can call functions to help you.
  #     To call a function, output a JSON object with the following format:
  #
  #       {
  #         "function": "<function name>",
  #         "arguments": {
  #           "<argument_name>": <argument_value>,
  #           ...
  #         }
  #       }
  #
  #     (Note: you cannot call other functions within arguments.)
  #
  #     The following functions are available:
  #
  #       function name: temperature_in_location
  #     description: Get the temperature in a location
  #     arguments:
  #       - location: Location, must be one of: 'Amsterdam', 'Utrecht', 'Enschede'
  #     - unit: Unit, must be one of: 'Celcius', 'Fahrenheit'
  #     return value: The temperature in the specified location and unit
  #
  #     After you call a function, wait until you receive more information.
  #     Use the information to decide your next steps or provide a final response.
  #   --- Receiving response from LLM provider: ---
  #     To get the weather in Enschede, I'll need to call the
  #     `temperature_in_location` function.
  #
  #   Here's my JSON object:
  #   ```
  #     {
  #       "function": "temperature_in_location",
  #       "arguments": {
  #         "location": "Enschede",
  #         "unit": "Celcius"
  #       }
  #     }
  #   ```
  #
  #   I'll wait for your response...
  # --- Sending request to LLM provider (llama3.1:8b): ---
  #   function called: temperature_in_location
  #   arguments used: location = Enschede, unit = Celcius
  #   result: 22.7
  # --- Receiving response from LLM provider: ---
  #   The current temperature in Enschede is 22.7째C.
  #
  #   So, the final answer is:
  #   **22.7째C**
  #
  #   Is there anything else I can help you with?
  # [1] "The current temperature in Enschede is 22.7째C.\n\nSo, the final answer
  # is:\n**22.7째C**\n\nIs there anything else I can help you with?"

  prompt2 |>
    send_prompt(llm_provider_ollama())
  # ...
}
}
\seealso{
\code{\link[=answer_as_code]{answer_as_code()}} \code{\link[=add_tools_get_documentation]{add_tools_get_documentation()}}

Other pre_built_prompt_wraps: 
\code{\link{add_text}()},
\code{\link{answer_as_boolean}()},
\code{\link{answer_as_code}()},
\code{\link{answer_as_integer}()},
\code{\link{answer_as_list}()},
\code{\link{answer_as_named_list}()},
\code{\link{answer_as_regex}()},
\code{\link{answer_by_chain_of_thought}()},
\code{\link{answer_by_react}()},
\code{\link{prompt_wrap}()},
\code{\link{quit_if}()},
\code{\link{set_system_prompt}()}

Other llm_tools: 
\code{\link{answer_as_code}()}

Other add_tools: 
\code{\link{add_tools_get_documentation}()}
}
\concept{add_tools}
\concept{llm_tools}
\concept{pre_built_prompt_wraps}
