% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_provider.R
\name{llm_provider-class}
\alias{llm_provider-class}
\title{Llm_provider R6 Class}
\description{
This class provides a structure for creating \link{llm_provider-class}
objects with different implementations of the \code{complete_chat} function. Using
this class, you can create an \link{llm_provider-class} object that interacts with
different LLM providers, such Ollama, OpenAI, or other custom providers.
}
\seealso{
Other llm_provider: 
\code{\link{llm_provider_google_gemini}()},
\code{\link{llm_provider_groq}()},
\code{\link{llm_provider_mistral}()},
\code{\link{llm_provider_ollama}()},
\code{\link{llm_provider_openai}()},
\code{\link{llm_provider_openrouter}()},
\code{\link{llm_provider_xai}()}
}
\concept{llm_provider}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{parameters}}{A named list of parameters to configure the
\link{llm_provider-class}. Parameters may be appended to the request body when
interacting with the LLM provider API}

\item{\code{verbose}}{A logical indicating whether interaction with the LLM
provider should be printed to the console}

\item{\code{url}}{The URL to the LLM provider API endpoint for chat completion}

\item{\code{api_key}}{The API key to use for authentication with the LLM
provider API}

\item{\code{api_type}}{The type of API to use (e.g., "openai", "ollama").
This is used to determine certain specific behaviors for different APIs,
for instance, as is done in the \code{\link[=answer_as_json]{answer_as_json()}} function}

\item{\code{handler_fns}}{A list of functions that will be called after the
completion of a chat. These functions can be used to modify the response
before it is returned to the user. Each function should take the response
object as input and return a modified response object. The functions will
be called in the order they are added to the list}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-Llm_provider-new}{\code{llm_provider-class$new()}}
\item \href{#method-Llm_provider-set_parameters}{\code{llm_provider-class$set_parameters()}}
\item \href{#method-Llm_provider-complete_chat}{\code{llm_provider-class$complete_chat()}}
\item \href{#method-Llm_provider-add_handler_fn}{\code{llm_provider-class$add_handler_fn()}}
\item \href{#method-Llm_provider-set_handler_fns}{\code{llm_provider-class$set_handler_fns()}}
\item \href{#method-Llm_provider-clone}{\code{llm_provider-class$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Llm_provider-new"></a>}}
\if{latex}{\out{\hypertarget{method-Llm_provider-new}{}}}
\subsection{Method \code{new()}}{
Create a new \link{llm_provider-class} object
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{llm_provider-class$new(
  complete_chat_function,
  parameters = list(),
  verbose = TRUE,
  url = NULL,
  api_key = NULL,
  api_type = "unspecified"
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{complete_chat_function}}{Function that will be called by the
\link{llm_provider-class} to complete a chat. This function should
take a list containing at least '$chat_history' (a data frame
with 'role' and 'content' columns) and return a response object, which contains:
\itemize{
\item 'completed': A dataframe with 'role' and 'content' columns,
containing the completed chat history
\item 'http': A list containing a list 'requests' and a list 'responses',
containing the HTTP requests and responses made during the chat completion
}}

\item{\code{parameters}}{A named list of parameters to configure the \link{llm_provider-class}.
These parameters may be appended to the request body when interacting with
the LLM provider. For example, the \code{model} parameter may often be required.
The 'stream' parameter may be used to indicate that the API should stream.
Parameters should not include the chat_history, or 'api_key' or 'url', which
are handled separately by the \link{llm_provider-class} and '$complete_chat()'.
Parameters should also not be set when they are handled by prompt wraps}

\item{\code{verbose}}{A logical indicating whether interaction with the LLM
provider should be printed to the console}

\item{\code{url}}{The URL to the LLM provider API endpoint for chat completion
(typically required, but may be left NULL in some cases, for instance
when creating a fake LLM provider)}

\item{\code{api_key}}{The API key to use for authentication with the LLM
provider API (optional, not required for, for instance, Ollama)}

\item{\code{api_type}}{The type of API to use (e.g., "openai", "ollama").
This is used to determine certain specific behaviors for different APIs
(see for example the \code{\link[=answer_as_json]{answer_as_json()}} function)}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new \link{llm_provider-class} R6 object
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Llm_provider-set_parameters"></a>}}
\if{latex}{\out{\hypertarget{method-Llm_provider-set_parameters}{}}}
\subsection{Method \code{set_parameters()}}{
Helper function to set the parameters of the \link{llm_provider-class}
object. This function appends new parameters to the existing parameters
list.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{llm_provider-class$set_parameters(new_parameters)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{new_parameters}}{A named list of new parameters to append to the
existing parameters list}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The modified \link{llm_provider-class} object
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Llm_provider-complete_chat"></a>}}
\if{latex}{\out{\hypertarget{method-Llm_provider-complete_chat}{}}}
\subsection{Method \code{complete_chat()}}{
complete_chat function; sends a chat_history to the LLM
provider using the configured \code{complete_chat_function}. This function is
typically called by the \code{send_prompt} function to interact with the LLM
provider, but it can also be called directly.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{llm_provider-class$complete_chat(input)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{input}}{A string, a data frame which is a valid chat history
(see \code{\link[=chat_history]{chat_history()}}), or a list containing a valid chat history under key
'#chat_history'}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The response from the LLM provider, in a named list
with 'role', 'content', and 'http'. The 'role' and 'content'
fields (required) contain the extracted role and content from the
response (e.g., 'assistant' and 'Hello, how can I help you?').
The 'http' field (optional) may contain any additional information, e.g.,
data from the HTTP response about the number of tokens used.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Llm_provider-add_handler_fn"></a>}}
\if{latex}{\out{\hypertarget{method-Llm_provider-add_handler_fn}{}}}
\subsection{Method \code{add_handler_fn()}}{
Helper function to add a handler function to the
\link{llm_provider-class} object. Handler functions are called after the
completion of a chat and can be used to modify the response before it is
returned to the user. Each handler function should take the response object
as input (1st argument) as well as 'self' (the \link{llm_provider-class}
object) and return a modified response object.The functions will be called
in the order they are added to the list.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{llm_provider-class$add_handler_fn(handler_fn)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{handler_fn}}{A function that takes the response object plus
'self' (the \link{llm_provider-class} object) as input and
returns a modified response object}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
If a handler function returns a list with a 'break' field set to TRUE,
the chat completion will be interrupted and the response will be returned at that point.
If a handler function returns a list with a 'done' field set to FALSE, the handler
functions will continue to be called in a loop until the 'done' field is not
set to FALSE
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Llm_provider-set_handler_fns"></a>}}
\if{latex}{\out{\hypertarget{method-Llm_provider-set_handler_fns}{}}}
\subsection{Method \code{set_handler_fns()}}{
Helper function to set the handler functions of the
\link{llm_provider-class} object. This function replaces the existing
handler functions list with a new list of handler functions. See
'$add_handler_fn()' for more information on handler functions
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{llm_provider-class$set_handler_fns(handler_fns)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{handler_fns}}{A list of handler functions to set}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Llm_provider-clone"></a>}}
\if{latex}{\out{\hypertarget{method-Llm_provider-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{llm_provider-class$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
